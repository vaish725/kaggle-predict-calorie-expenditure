{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5289078b",
   "metadata": {},
   "source": [
    "# Step 4: XGBoost Hyperparameter Tuning\n",
    "\n",
    "In this notebook, we use Optuna, a hyperparameter optimization framework, to find the best XGBoost configuration for our calorie expenditure prediction task.\n",
    "\n",
    "## Why XGBoost?\n",
    "- Gradient boosting algorithms typically perform well on tabular data\n",
    "- Handles a mix of feature types and scales effectively\n",
    "- Built-in regularization to prevent overfitting\n",
    "- Captures both linear and non-linear relationships\n",
    "\n",
    "## Why Optuna?\n",
    "- Efficient Bayesian optimization algorithms\n",
    "- Automatic pruning of unpromising trials\n",
    "- Parallel computation support\n",
    "- Visualization capabilities for understanding hyperparameter importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6c31c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\vkvai\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\vkvai\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\vkvai\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: xgboost in c:\\users\\vkvai\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.0.1)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\vkvai\\appdata\\roaming\\python\\python311\\site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vkvai\\appdata\\roaming\\python\\python311\\site-packages (from optuna) (23.2)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Downloading sqlalchemy-2.0.41-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vkvai\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\vkvai\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\vkvai\\appdata\\roaming\\python\\python311\\site-packages (from xgboost) (1.12.0)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\vkvai\\appdata\\roaming\\python\\python311\\site-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Downloading greenlet-3.2.2-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\vkvai\\appdata\\roaming\\python\\python311\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\vkvai\\appdata\\roaming\\python\\python311\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
      "Downloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 23.7 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.2.2-cp311-cp311-win_amd64.whl (295 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "\n",
      "   ---------------------------------------- 0/6 [Mako]\n",
      "   ---------------------------------------- 0/6 [Mako]\n",
      "   ---------------------------------------- 0/6 [Mako]\n",
      "   ---------------------------------------- 0/6 [Mako]\n",
      "   ------ --------------------------------- 1/6 [greenlet]\n",
      "   ------ --------------------------------- 1/6 [greenlet]\n",
      "   ------ --------------------------------- 1/6 [greenlet]\n",
      "   ------------- -------------------------- 2/6 [colorlog]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------- ------------------- 3/6 [sqlalchemy]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   -------------------------- ------------- 4/6 [alembic]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   --------------------------------- ------ 5/6 [optuna]\n",
      "   ---------------------------------------- 6/6 [optuna]\n",
      "\n",
      "Successfully installed Mako-1.3.10 alembic-1.15.2 colorlog-6.9.0 greenlet-3.2.2 optuna-4.3.0 sqlalchemy-2.0.41\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries if not already present\n",
    "!pip install optuna xgboost\n",
    "\n",
    "# Import necessary libraries\n",
    "import optuna  # For hyperparameter optimization\n",
    "import pandas as pd  # For data manipulation\n",
    "import numpy as np  # For numerical operations\n",
    "from sklearn.model_selection import cross_val_score, KFold  # For cross-validation\n",
    "from xgboost import XGBRegressor  # XGBoost implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ac85a8",
   "metadata": {},
   "source": [
    "## 1. Load Feature-Engineered Training Data\n",
    "\n",
    "This dataset contains all the features we created in the feature engineering step (feature_engineering_step2b.ipynb).\n",
    "The dataset includes both original features and engineered features like polynomial terms and interaction features.\n",
    "\n",
    "Note: For XGBoost, we use the raw Calories values rather than log-transformed ones, as XGBoost can handle\n",
    "non-normal distributions well. However, we'll still evaluate using RMSLE (Root Mean Squared Log Error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d593f774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the feature-engineered training dataset\n",
    "train = pd.read_csv('datasets/train_fe.csv')\n",
    "\n",
    "# Separate target variable (Calories) and features\n",
    "y = train['Calories']  # Target variable\n",
    "X = train.drop(columns='Calories')  # Feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1cf80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to evaluate models using Root Mean Squared Log Error (RMSLE)\n",
    "# via 5-fold cross-validation\n",
    "def rmsle_cv(model):\n",
    "    # Create 5-fold cross-validation splits with fixed random seed for reproducibility\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Calculate negative MSLE scores across all folds\n",
    "    # Note: sklearn returns negative scores for metrics where lower is better\n",
    "    scores = -cross_val_score(model, X, y, scoring=\"neg_mean_squared_log_error\", cv=kf, n_jobs=-1)\n",
    "    \n",
    "    # Return the square root of the mean score (RMSLE)\n",
    "    return np.sqrt(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78a449b",
   "metadata": {},
   "source": [
    "## 2. Define Optuna Objective Function\n",
    "\n",
    "The objective function defines what we want to optimize (minimize RMSLE in our case).\n",
    "It creates an XGBoost model with parameters suggested by Optuna and evaluates it using cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bad2e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna to minimize\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 300, 1000),  # Number of boosting rounds\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 10),            # Maximum tree depth\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),  # Learning rate (eta)\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),       # Subsample ratio of training data\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),  # Feature subsampling ratio\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),                   # Minimum loss reduction for split\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 5),           # L1 regularization\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 5),         # L2 regularization\n",
    "        'random_state': 42,  # For reproducibility\n",
    "        'n_jobs': -1         # Use all available CPU cores\n",
    "    }\n",
    "\n",
    "    # Create XGBoost model with the suggested parameters\n",
    "    model = XGBRegressor(**params)\n",
    "    \n",
    "    # Return RMSLE score (lower is better)\n",
    "    return rmsle_cv(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1010bf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-20 16:53:52,718] A new study created in memory with name: no-name-3e057a1c-902a-4a5b-ac05-6e37b99b6a65\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0428227eef29416bb20ffda9b91bd10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-05-20 16:54:22,695] Trial 0 finished with value: 0.0175326463663772 and parameters: {'n_estimators': 578, 'max_depth': 8, 'learning_rate': 0.28150303899633333, 'subsample': 0.8451286232509485, 'colsample_bytree': 0.8621780128576577, 'gamma': 0.04994641396930677, 'reg_alpha': 1.0994169717138007, 'reg_lambda': 2.806855569115347}. Best is trial 0 with value: 0.0175326463663772.\n",
      "[I 2025-05-20 16:54:42,568] Trial 1 finished with value: 0.01841559479917221 and parameters: {'n_estimators': 406, 'max_depth': 5, 'learning_rate': 0.1665008027620495, 'subsample': 0.891553116896902, 'colsample_bytree': 0.9017646206016794, 'gamma': 2.4755901597006087, 'reg_alpha': 4.572622877455029, 'reg_lambda': 4.127360945205066}. Best is trial 0 with value: 0.0175326463663772.\n",
      "[I 2025-05-20 16:54:58,658] Trial 2 finished with value: 0.018115600101071418 and parameters: {'n_estimators': 322, 'max_depth': 10, 'learning_rate': 0.2243484540748487, 'subsample': 0.9799274954878197, 'colsample_bytree': 0.6661085794803393, 'gamma': 3.503304908357178, 'reg_alpha': 3.17692533397925, 'reg_lambda': 0.932099659863726}. Best is trial 0 with value: 0.0175326463663772.\n",
      "[I 2025-05-20 16:55:56,029] Trial 3 finished with value: 0.017825332872137726 and parameters: {'n_estimators': 670, 'max_depth': 7, 'learning_rate': 0.020349834139978012, 'subsample': 0.7498953371847716, 'colsample_bytree': 0.7064215504569777, 'gamma': 2.570370554124045, 'reg_alpha': 3.8346200936372092, 'reg_lambda': 1.2519791418592345}. Best is trial 0 with value: 0.0175326463663772.\n",
      "[I 2025-05-20 16:56:21,788] Trial 4 finished with value: 0.018002521211154324 and parameters: {'n_estimators': 306, 'max_depth': 9, 'learning_rate': 0.04731059116467044, 'subsample': 0.8096282420526942, 'colsample_bytree': 0.75092016211821, 'gamma': 4.011896981276765, 'reg_alpha': 4.927637693066581, 'reg_lambda': 1.6123451896582763}. Best is trial 0 with value: 0.0175326463663772.\n",
      "[I 2025-05-20 16:57:00,168] Trial 5 finished with value: 0.01766601350239122 and parameters: {'n_estimators': 870, 'max_depth': 6, 'learning_rate': 0.10259151952959353, 'subsample': 0.9427981367306956, 'colsample_bytree': 0.7079870887417946, 'gamma': 0.5361930928134134, 'reg_alpha': 2.240047952015147, 'reg_lambda': 1.836533579913155}. Best is trial 0 with value: 0.0175326463663772.\n",
      "[I 2025-05-20 16:57:29,834] Trial 6 finished with value: 0.01821084586278267 and parameters: {'n_estimators': 770, 'max_depth': 5, 'learning_rate': 0.1922595623834049, 'subsample': 0.9867451738316861, 'colsample_bytree': 0.9587303748760898, 'gamma': 0.8613091655710514, 'reg_alpha': 1.6044657857954419, 'reg_lambda': 0.7208524130316946}. Best is trial 0 with value: 0.0175326463663772.\n",
      "[I 2025-05-20 16:58:18,489] Trial 7 finished with value: 0.017752378764060085 and parameters: {'n_estimators': 911, 'max_depth': 6, 'learning_rate': 0.04111251970916092, 'subsample': 0.812935563924731, 'colsample_bytree': 0.8784051669146871, 'gamma': 1.3840378394570334, 'reg_alpha': 1.2919457263164906, 'reg_lambda': 4.374225996868465}. Best is trial 0 with value: 0.0175326463663772.\n",
      "[I 2025-05-20 16:59:41,052] Trial 8 finished with value: 0.017176983320523774 and parameters: {'n_estimators': 793, 'max_depth': 10, 'learning_rate': 0.04243279044754314, 'subsample': 0.7656570298018519, 'colsample_bytree': 0.6144759754099026, 'gamma': 0.019791322584708504, 'reg_alpha': 4.216385830811575, 'reg_lambda': 4.701860424009831}. Best is trial 8 with value: 0.017176983320523774.\n",
      "[I 2025-05-20 17:00:23,674] Trial 9 finished with value: 0.018883862182559212 and parameters: {'n_estimators': 954, 'max_depth': 4, 'learning_rate': 0.14661869723792703, 'subsample': 0.9136768581634839, 'colsample_bytree': 0.978562590178869, 'gamma': 4.607933127287303, 'reg_alpha': 3.483862052020586, 'reg_lambda': 1.2331017909041315}. Best is trial 8 with value: 0.017176983320523774.\n",
      "[I 2025-05-20 17:00:55,501] Trial 10 finished with value: 0.017880723830374104 and parameters: {'n_estimators': 533, 'max_depth': 10, 'learning_rate': 0.09990661610720508, 'subsample': 0.6061987009230868, 'colsample_bytree': 0.6090474015625339, 'gamma': 1.7835686689287922, 'reg_alpha': 0.11340450696975157, 'reg_lambda': 3.2646882568769025}. Best is trial 8 with value: 0.017176983320523774.\n",
      "[I 2025-05-20 17:01:24,899] Trial 11 finished with value: 0.017599953714229087 and parameters: {'n_estimators': 583, 'max_depth': 8, 'learning_rate': 0.29228771338824805, 'subsample': 0.7320904279487961, 'colsample_bytree': 0.8228307324931657, 'gamma': 0.08589182130355194, 'reg_alpha': 0.2677605675052308, 'reg_lambda': 2.993083430426261}. Best is trial 8 with value: 0.017176983320523774.\n",
      "[I 2025-05-20 17:01:58,836] Trial 12 finished with value: 0.01780700706751941 and parameters: {'n_estimators': 734, 'max_depth': 8, 'learning_rate': 0.2923384693094774, 'subsample': 0.6764447332306373, 'colsample_bytree': 0.8042669637780941, 'gamma': 0.30401645553292556, 'reg_alpha': 1.1616938403702353, 'reg_lambda': 4.8607050230628435}. Best is trial 8 with value: 0.017176983320523774.\n",
      "[I 2025-05-20 17:02:23,252] Trial 13 finished with value: 0.017912496545876597 and parameters: {'n_estimators': 497, 'max_depth': 9, 'learning_rate': 0.23741398996024146, 'subsample': 0.848902648890088, 'colsample_bytree': 0.8888012173895061, 'gamma': 1.5089439849139024, 'reg_alpha': 2.6023858159474664, 'reg_lambda': 0.13878237363233037}. Best is trial 8 with value: 0.017176983320523774.\n",
      "[I 2025-05-20 17:04:23,065] Trial 14 finished with value: 0.0171680104690813 and parameters: {'n_estimators': 792, 'max_depth': 9, 'learning_rate': 0.09223410462196788, 'subsample': 0.7451829870376107, 'colsample_bytree': 0.6110791267506638, 'gamma': 0.0026950105357177664, 'reg_alpha': 4.028764988128403, 'reg_lambda': 3.536679044997298}. Best is trial 14 with value: 0.0171680104690813.\n",
      "[I 2025-05-20 17:05:05,924] Trial 15 finished with value: 0.01773756237983441 and parameters: {'n_estimators': 795, 'max_depth': 10, 'learning_rate': 0.09246664500962727, 'subsample': 0.7330225319828277, 'colsample_bytree': 0.6082424128805419, 'gamma': 0.9375896514161807, 'reg_alpha': 4.2023826292028605, 'reg_lambda': 3.616226379929545}. Best is trial 14 with value: 0.0171680104690813.\n",
      "[I 2025-05-20 17:05:52,649] Trial 16 finished with value: 0.017872548550847057 and parameters: {'n_estimators': 841, 'max_depth': 9, 'learning_rate': 0.07229046119016015, 'subsample': 0.6687075929149611, 'colsample_bytree': 0.6534560510284085, 'gamma': 2.4180013244082694, 'reg_alpha': 2.9867184307156296, 'reg_lambda': 4.928053589453442}. Best is trial 14 with value: 0.0171680104690813.\n",
      "[I 2025-05-20 17:06:37,304] Trial 17 finished with value: 0.017646733849141626 and parameters: {'n_estimators': 987, 'max_depth': 9, 'learning_rate': 0.14095039124160166, 'subsample': 0.7625555845277858, 'colsample_bytree': 0.7491484604804833, 'gamma': 0.8993409365844323, 'reg_alpha': 3.9889185704300685, 'reg_lambda': 3.875535534743892}. Best is trial 14 with value: 0.0171680104690813.\n",
      "[I 2025-05-20 17:07:39,152] Trial 18 finished with value: 0.017759508757989456 and parameters: {'n_estimators': 682, 'max_depth': 10, 'learning_rate': 0.020053601394975126, 'subsample': 0.6772396706262842, 'colsample_bytree': 0.654471652307705, 'gamma': 1.9203239574963855, 'reg_alpha': 4.983969171271941, 'reg_lambda': 2.288899989516579}. Best is trial 14 with value: 0.0171680104690813.\n",
      "[I 2025-05-20 17:08:14,902] Trial 19 finished with value: 0.01811106751394849 and parameters: {'n_estimators': 725, 'max_depth': 7, 'learning_rate': 0.06809507911611622, 'subsample': 0.7775027642256739, 'colsample_bytree': 0.6065257812275308, 'gamma': 3.4611485556940274, 'reg_alpha': 4.337779531335549, 'reg_lambda': 4.518044066544842}. Best is trial 14 with value: 0.0171680104690813.\n",
      "[I 2025-05-20 17:08:51,783] Trial 20 finished with value: 0.017685865039914914 and parameters: {'n_estimators': 819, 'max_depth': 8, 'learning_rate': 0.12296580271753602, 'subsample': 0.6065505511032334, 'colsample_bytree': 0.7008588530583211, 'gamma': 0.7915641840111871, 'reg_alpha': 3.6482005339956256, 'reg_lambda': 3.498873629725335}. Best is trial 14 with value: 0.0171680104690813.\n",
      "[I 2025-05-20 17:09:30,279] Trial 21 finished with value: 0.01746187107635435 and parameters: {'n_estimators': 626, 'max_depth': 8, 'learning_rate': 0.2505407609276064, 'subsample': 0.8513592817052733, 'colsample_bytree': 0.834008246029539, 'gamma': 0.008656109992095488, 'reg_alpha': 1.8991422489864216, 'reg_lambda': 2.7209132141457317}. Best is trial 14 with value: 0.0171680104690813.\n",
      "[I 2025-05-20 17:10:07,608] Trial 22 finished with value: 0.01738318094801289 and parameters: {'n_estimators': 610, 'max_depth': 9, 'learning_rate': 0.0629266770946276, 'subsample': 0.8628706269122666, 'colsample_bytree': 0.7657472691217095, 'gamma': 0.47166353812416334, 'reg_alpha': 2.1207670563081416, 'reg_lambda': 2.314168589701471}. Best is trial 14 with value: 0.0171680104690813.\n",
      "[I 2025-05-20 17:10:48,807] Trial 23 finished with value: 0.017415629090806607 and parameters: {'n_estimators': 711, 'max_depth': 9, 'learning_rate': 0.0624361146878917, 'subsample': 0.7122462971865413, 'colsample_bytree': 0.7680183220661628, 'gamma': 0.45304854068328754, 'reg_alpha': 2.7683349416825327, 'reg_lambda': 2.259392004168949}. Best is trial 14 with value: 0.0171680104690813.\n",
      "[I 2025-05-20 17:12:07,287] Trial 24 finished with value: 0.017705873501335796 and parameters: {'n_estimators': 469, 'max_depth': 10, 'learning_rate': 0.01307084004353759, 'subsample': 0.7887460019384507, 'colsample_bytree': 0.6412734329069366, 'gamma': 1.287094552232586, 'reg_alpha': 3.335903584714103, 'reg_lambda': 3.931011558417495}. Best is trial 14 with value: 0.0171680104690813.\n",
      "[I 2025-05-20 17:13:04,483] Trial 25 finished with value: 0.017368100972284337 and parameters: {'n_estimators': 901, 'max_depth': 9, 'learning_rate': 0.042314783575728425, 'subsample': 0.8771991821338317, 'colsample_bytree': 0.6896656705948068, 'gamma': 0.4668345425308902, 'reg_alpha': 2.2405521391378946, 'reg_lambda': 3.2969552801795876}. Best is trial 14 with value: 0.0171680104690813.\n",
      "[I 2025-05-20 17:14:01,425] Trial 26 finished with value: 0.01757756993594808 and parameters: {'n_estimators': 918, 'max_depth': 10, 'learning_rate': 0.037898232419402864, 'subsample': 0.8164960634827378, 'colsample_bytree': 0.6873802830892232, 'gamma': 1.1303273726331944, 'reg_alpha': 4.446102664377361, 'reg_lambda': 3.2144375944243997}. Best is trial 14 with value: 0.0171680104690813.\n",
      "[I 2025-05-20 17:14:46,109] Trial 27 finished with value: 0.017590191552880014 and parameters: {'n_estimators': 878, 'max_depth': 9, 'learning_rate': 0.08666470635022187, 'subsample': 0.7124074217035219, 'colsample_bytree': 0.6308180456399067, 'gamma': 0.6157620285148463, 'reg_alpha': 2.873869911268346, 'reg_lambda': 4.484647014798928}. Best is trial 14 with value: 0.0171680104690813.\n",
      "[I 2025-05-20 17:15:24,570] Trial 28 finished with value: 0.01777271489273463 and parameters: {'n_estimators': 830, 'max_depth': 10, 'learning_rate': 0.11850558110009196, 'subsample': 0.8924953327062638, 'colsample_bytree': 0.6758502623233971, 'gamma': 1.9095461554396422, 'reg_alpha': 2.4751061483855, 'reg_lambda': 3.6874836894211707}. Best is trial 14 with value: 0.0171680104690813.\n",
      "[I 2025-05-20 17:16:39,627] Trial 29 finished with value: 0.017111849099572106 and parameters: {'n_estimators': 761, 'max_depth': 8, 'learning_rate': 0.04329564685888236, 'subsample': 0.829156412199964, 'colsample_bytree': 0.6293472330739741, 'gamma': 0.025125225652620986, 'reg_alpha': 0.8448922499045819, 'reg_lambda': 2.784200742308772}. Best is trial 29 with value: 0.017111849099572106.\n",
      "Best trial:\n",
      "FrozenTrial(number=29, state=1, values=[0.017111849099572106], datetime_start=datetime.datetime(2025, 5, 20, 17, 15, 24, 573902), datetime_complete=datetime.datetime(2025, 5, 20, 17, 16, 39, 627379), params={'n_estimators': 761, 'max_depth': 8, 'learning_rate': 0.04329564685888236, 'subsample': 0.829156412199964, 'colsample_bytree': 0.6293472330739741, 'gamma': 0.025125225652620986, 'reg_alpha': 0.8448922499045819, 'reg_lambda': 2.784200742308772}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=1000, log=False, low=300, step=1), 'max_depth': IntDistribution(high=10, log=False, low=4, step=1), 'learning_rate': FloatDistribution(high=0.3, log=False, low=0.01, step=None), 'subsample': FloatDistribution(high=1.0, log=False, low=0.6, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.6, step=None), 'gamma': FloatDistribution(high=5.0, log=False, low=0.0, step=None), 'reg_alpha': FloatDistribution(high=5.0, log=False, low=0.0, step=None), 'reg_lambda': FloatDistribution(high=5.0, log=False, low=0.0, step=None)}, trial_id=29, value=None)\n"
     ]
    }
   ],
   "source": [
    "# Create an Optuna study object\n",
    "# Direction='minimize' because we want to minimize RMSLE\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# Run the optimization process with 30 trials\n",
    "# Each trial tests a different hyperparameter combination\n",
    "study.optimize(objective, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "# Print the best trial information\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af73f1e5",
   "metadata": {},
   "source": [
    "## 3. Train Final XGBoost Model with Best Parameters\n",
    "\n",
    "Now that Optuna has found the optimal hyperparameters, we'll:\n",
    "1. Extract the best parameter set\n",
    "2. Train a final model using these parameters\n",
    "3. Use this model for making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b55a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.6293472330739741, device=None,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, feature_weights=None,\n",
       "             gamma=0.025125225652620986, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.04329564685888236,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=761, n_jobs=None,\n",
       "             num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.6293472330739741, device=None,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, feature_weights=None,\n",
       "             gamma=0.025125225652620986, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.04329564685888236,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=761, n_jobs=None,\n",
       "             num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.6293472330739741, device=None,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, feature_weights=None,\n",
       "             gamma=0.025125225652620986, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.04329564685888236,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=761, n_jobs=None,\n",
       "             num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the best parameters found during optimization\n",
    "best_params = study.best_trial.params\n",
    "\n",
    "# Train the final XGBoost model with the best parameters\n",
    "best_model = XGBRegressor(**best_params)\n",
    "best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c27bdc",
   "metadata": {},
   "source": [
    "### üèÜ Best XGBoost Parameters from Trial 29\n",
    "\n",
    "These optimized hyperparameters represent our best configuration after 30 trials.\n",
    "Each parameter plays a specific role in the model's performance:\n",
    "\n",
    "| Parameter          | Value                       | Purpose                                             |\n",
    "| ------------------ | --------------------------- | --------------------------------------------------- |\n",
    "| `n_estimators`     | 761                         | Number of trees in the ensemble                      |\n",
    "| `max_depth`        | 8                           | Maximum tree depth (controls model complexity)       |\n",
    "| `learning_rate`    | 0.0433                      | Step size shrinkage to prevent overfitting           |\n",
    "| `subsample`        | 0.8292                      | Fraction of samples used for fitting trees           |\n",
    "| `colsample_bytree` | 0.6293                      | Fraction of features used for fitting each tree      |\n",
    "| `gamma`            | 0.0251                      | Minimum loss reduction for a split                   |\n",
    "| `reg_alpha`        | 0.8449                      | L1 regularization on weights                        |\n",
    "| `reg_lambda`       | 2.7842                      | L2 regularization on weights                        |\n",
    "| **RMSLE**          | **0.01711** ‚úÖ (best so far) | Our evaluation metric - lower is better             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a017b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Load the feature-engineered test data\n",
    "test = pd.read_csv(\"datasets/test_fe.csv\")\n",
    "\n",
    "# Load test IDs for submission file\n",
    "test_ids = pd.read_csv(\"datasets/test_ids.csv\")['id']\n",
    "\n",
    "# Recreate the best model with exact parameters from optimization\n",
    "best_model = XGBRegressor(\n",
    "    n_estimators=761,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.04329564685888236,\n",
    "    subsample=0.829156412199964,\n",
    "    colsample_bytree=0.6293472330739741,\n",
    "    gamma=0.025125225652620986,\n",
    "    reg_alpha=0.8448922499045819,\n",
    "    reg_lambda=2.784200742308772,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ") the full feature-engineered training data\n",
    "\n",
    "best_model.fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_preds = np.expm1(test_preds_log)# Reverse the log1p transformation to get final predictionstest_preds_log = best_model.predict(test)# Predict on the test set (log-transformed target)# Make predictions on test data\n",
    "test_preds_log = best_model.predict(test)\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "# Note: If we had log-transformed the target, we'd need to convert back\n",
    "test_preds = np.expm1(test_preds_log)  # reverse log1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5874bd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file 'submission_xgb_tuned_may20.csv' created.\n"
     ]
    }
   ],
   "source": [
    "# Create a submission dataframe with the required format\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,        # Test sample IDs\n",
    "    'Calories': test_preds # Predicted calorie values\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv(\"datasets/submissions/submission_xgb_tuned_may20.csv\", index=False)\n",
    "print(\"Submission file 'submission_xgb_tuned_may20.csv' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876dfdd2",
   "metadata": {},
   "source": [
    "# Summary of XGBoost Tuning\n",
    "\n",
    "## Key Findings:\n",
    "\n",
    "1. **Best RMSLE:** 0.01711 - A significant improvement over baseline models\n",
    "\n",
    "2. **Important Parameters:**\n",
    "   - Higher number of estimators (761) indicate model benefits from ensemble power\n",
    "   - Moderate tree depth (8) suggests moderate complexity is sufficient\n",
    "   - Low learning rate (0.0433) helps with generalization\n",
    "   - Higher L2 than L1 regularization suggest smoothing is important\n",
    "\n",
    "3. **Next Steps:**\n",
    "   - Use these parameters for ensemble models\n",
    "   - Try SHAP analysis to understand feature contributions\n",
    "   - Consider further feature engineering based on model insights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
